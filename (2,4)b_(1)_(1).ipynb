{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(2,4)b_(1)_(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Required Libraries  "
      ],
      "metadata": {
        "id": "CW8m7EYH-NH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rpECXu6zYkIF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Input, Dense, GaussianNoise,Lambda\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras.constraints import max_norm \n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(3)                                                 \n",
        "from scipy import interpolate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters Declaration \n",
        "Lenght of Message space, Number of bits per symbol, number of channel uses\n",
        "and Rate of communication is defined here. "
      ],
      "metadata": {
        "id": "2zTzktIN_LAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L_o_m  = 16                                  # Lenght of Message space(M) given by 2^number of bits \n",
        "bits = np.log2(L_o_m)                        # Number of bits \n",
        "bits = int(bits)                             # Converting it to int \n",
        "n = 2                                        # Number of channels(n) \n",
        "R = bits/n                                   # Communication rate(R) given by number of bits divided by number of channels\n",
        "\n",
        "print ('Lenght of Message space (M):',L_o_m,'Number of bits (k):',bits,'Number of channels (n):',n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqlokJnxa0P-",
        "outputId": "6385c752-4c2f-42d1-be93-d2bdf04250e6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of Message space (M): 16 Number of bits (k): 4 Number of channels (n): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating training data"
      ],
      "metadata": {
        "id": "rHe_SSueADk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = 100000\n",
        "labels = np.random.randint(L_o_m , size=samples)    # generating N random numbers whose values are enclosed between 0 and (M-1)"
      ],
      "metadata": {
        "id": "01xhM5MWa4Jl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Onehot Encoding\n",
        "Each of the message in generated message space is onehot encoded. "
      ],
      "metadata": {
        "id": "TJPJNPzJAko9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []                                  # Creating a empty list \n",
        "for i in labels:                         \n",
        "    inp_vector = np.zeros(L_o_m)                    # Creating a numpy array of size M                                                    \n",
        "    inp_vector[i] = 1                               # Performing one hot encoding \n",
        "    training_data.append(inp_vector) \n",
        "\n"
      ],
      "metadata": {
        "id": "fZA-OwDvboBl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = np.array(training_data)             # Transforming data to numpy array\n",
        "print (training_data.shape)                         # Each of the sample out of the N generated samples is onehot encoded to vector of size M "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ppnpj4ubrsF",
        "outputId": "eb47ed7d-b218-4a8f-c459-29a5bc5024b4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifying the one hot encoding performed on the generated data.  \n"
      ],
      "metadata": {
        "id": "diWa01MlD-ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_list = [23,45,97,115,278,369]                # Verifying the one hot encoding performed on the generated data.\n",
        "for i in check_list:\n",
        "    print(labels[i],training_data[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwwdatTObvhc",
        "outputId": "a1564df5-2aee-4cf3-b726-91d84e984176"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "2 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the architecture of Autoencoder"
      ],
      "metadata": {
        "id": "H2uQEQoIFBWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_signal = Input(shape=(L_o_m,))                       # After performing one hot encoding each input is vector of size M\n",
        "encoded1 = Dense(L_o_m, activation='relu')(input_signal)   # First layer is dense layer with relu activation function and M nuerons  \n",
        "encoded2 = Dense(n, activation='linear')(encoded1)         # Second layer is dense layer with linear activaton function and n_channel nuerons \n",
        "\n",
        "encoded3 = BatchNormalization(gamma_constraint=max_norm(1.4142136))(encoded2) \n",
        "                                                           #encoded3 = Lambda(lambda x: np.sqrt(n)*K.l2_normalize(x,axis=1))(encoded2)      \n",
        "                                                           # Normalisation is performed to met the physical constraints (Energy Constraint)\n",
        "\n",
        "EbNo_train = 5.01187                                       # coverted 7 db of EbNo\n",
        "                                                           # 10log(EbNo) = 7 db\n",
        "\n",
        "encoded4 = GaussianNoise(np.sqrt(1/(2*R*EbNo_train)))(encoded3)                 \n",
        "                                                           # As Variance is given by (1/(2*R*EbNo_train) \n",
        "                                                           # Gausian noise is added by this layer \n",
        "\n",
        "decoded1 = Dense(L_o_m, activation='relu')(encoded4)       # First layer of the decoder is dense layer with- \n",
        "                                                           #-relu activation function and total M nuerons\n",
        "\n",
        "decoded2 = Dense(L_o_m, activation='softmax')(decoded1)    # Second layer of the decoder is dense layer with-\n",
        "                                                           #-softmax activation function which outputs the probabilities \n",
        "\n",
        "\n",
        "autoencoder = Model(input_signal, decoded2)                # Autoencoder model is defined here \n",
        "adam = Adam(learning_rate=0.001)                           # Adam optimizer is used with learning rate 0.001 to minimise the loss \n",
        "\n",
        "autoencoder.compile(optimizer=adam, loss='categorical_crossentropy')            \n",
        "                                                           # Autoencoder is compiled here and loss is defined as categorical crossentropy- \n",
        "                                                           #-between the onehot encoded input vector and the output of the decoder "
      ],
      "metadata": {
        "id": "-FNphna1bxfk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary of Autoencoder"
      ],
      "metadata": {
        "id": "7xS2b5trFX2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (autoencoder.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o2A_DywcfK1",
        "outputId": "ee58fd5b-a01d-4449-a255-fd7ae7f4c3b3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 16)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 2)                8         \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " gaussian_noise (GaussianNoi  (None, 2)                0         \n",
            " se)                                                             \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                48        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 634\n",
            "Trainable params: 630\n",
            "Non-trainable params: 4\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model "
      ],
      "metadata": {
        "id": "KsIqAPGUFjdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(training_data, training_data, epochs=150, batch_size=64)        # Autoencoder is fitted with the generated data                                         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zk1GFPac4-M",
        "outputId": "b6c67967-8713-4145-8ec6-1e8a4e5cd479"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1563/1563 [==============================] - 7s 3ms/step - loss: 1.2055\n",
            "Epoch 2/150\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.5123\n",
            "Epoch 3/150\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.3799\n",
            "Epoch 4/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3494\n",
            "Epoch 5/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3361\n",
            "Epoch 6/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3337\n",
            "Epoch 7/150\n",
            "1563/1563 [==============================] - 2s 2ms/step - loss: 0.3316\n",
            "Epoch 8/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3257\n",
            "Epoch 9/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3196\n",
            "Epoch 10/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3244\n",
            "Epoch 11/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3214\n",
            "Epoch 12/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3175\n",
            "Epoch 13/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3249\n",
            "Epoch 14/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3175\n",
            "Epoch 15/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3195\n",
            "Epoch 16/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3147\n",
            "Epoch 17/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3187\n",
            "Epoch 18/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3203\n",
            "Epoch 19/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3108\n",
            "Epoch 20/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3191\n",
            "Epoch 21/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3153\n",
            "Epoch 22/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3215\n",
            "Epoch 23/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3225\n",
            "Epoch 24/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3177\n",
            "Epoch 25/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3128\n",
            "Epoch 26/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3143\n",
            "Epoch 27/150\n",
            "1563/1563 [==============================] - 2s 2ms/step - loss: 0.3059\n",
            "Epoch 28/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3167\n",
            "Epoch 29/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3188\n",
            "Epoch 30/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3151\n",
            "Epoch 31/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3208\n",
            "Epoch 32/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3101\n",
            "Epoch 33/150\n",
            "1563/1563 [==============================] - 2s 2ms/step - loss: 0.3155\n",
            "Epoch 34/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3112\n",
            "Epoch 35/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3213\n",
            "Epoch 36/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3125\n",
            "Epoch 37/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3075\n",
            "Epoch 38/150\n",
            "1563/1563 [==============================] - 2s 2ms/step - loss: 0.3109\n",
            "Epoch 39/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3173\n",
            "Epoch 40/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3111\n",
            "Epoch 41/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3203\n",
            "Epoch 42/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3187\n",
            "Epoch 43/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3172\n",
            "Epoch 44/150\n",
            "1563/1563 [==============================] - 2s 2ms/step - loss: 0.3116\n",
            "Epoch 45/150\n",
            "1563/1563 [==============================] - 4s 2ms/step - loss: 0.3141\n",
            "Epoch 46/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3104\n",
            "Epoch 47/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3105\n",
            "Epoch 48/150\n",
            "1563/1563 [==============================] - 2s 2ms/step - loss: 0.3248\n",
            "Epoch 49/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3172\n",
            "Epoch 50/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3173\n",
            "Epoch 51/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3132\n",
            "Epoch 52/150\n",
            "1563/1563 [==============================] - 2s 2ms/step - loss: 0.3101\n",
            "Epoch 53/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3179\n",
            "Epoch 54/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3190\n",
            "Epoch 55/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3114\n",
            "Epoch 56/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3156\n",
            "Epoch 57/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3152\n",
            "Epoch 58/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3179\n",
            "Epoch 59/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3108\n",
            "Epoch 60/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3127\n",
            "Epoch 61/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3178\n",
            "Epoch 62/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3153\n",
            "Epoch 63/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3145\n",
            "Epoch 64/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3188\n",
            "Epoch 65/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3184\n",
            "Epoch 66/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3151\n",
            "Epoch 67/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3154\n",
            "Epoch 68/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3227\n",
            "Epoch 69/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3204\n",
            "Epoch 70/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3206\n",
            "Epoch 71/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3107\n",
            "Epoch 72/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3126\n",
            "Epoch 73/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3113\n",
            "Epoch 74/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3197\n",
            "Epoch 75/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3083\n",
            "Epoch 76/150\n",
            "1563/1563 [==============================] - 2s 2ms/step - loss: 0.3128\n",
            "Epoch 77/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3220\n",
            "Epoch 78/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3070\n",
            "Epoch 79/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3116\n",
            "Epoch 80/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3119\n",
            "Epoch 81/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3106\n",
            "Epoch 82/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3168\n",
            "Epoch 83/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3194\n",
            "Epoch 84/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3190\n",
            "Epoch 85/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3116\n",
            "Epoch 86/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3118\n",
            "Epoch 87/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3068\n",
            "Epoch 88/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3099\n",
            "Epoch 89/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3155\n",
            "Epoch 90/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3058\n",
            "Epoch 91/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3123\n",
            "Epoch 92/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3093\n",
            "Epoch 93/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3167\n",
            "Epoch 94/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3110\n",
            "Epoch 95/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3100\n",
            "Epoch 96/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3198\n",
            "Epoch 97/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3088\n",
            "Epoch 98/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3161\n",
            "Epoch 99/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3089\n",
            "Epoch 100/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3085\n",
            "Epoch 101/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3159\n",
            "Epoch 102/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3123\n",
            "Epoch 103/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3100\n",
            "Epoch 104/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3173\n",
            "Epoch 105/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3055\n",
            "Epoch 106/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3232\n",
            "Epoch 107/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3049\n",
            "Epoch 108/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3104\n",
            "Epoch 109/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3048\n",
            "Epoch 110/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3135\n",
            "Epoch 111/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3144\n",
            "Epoch 112/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3155\n",
            "Epoch 113/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3062\n",
            "Epoch 114/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3025\n",
            "Epoch 115/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3087\n",
            "Epoch 116/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3098\n",
            "Epoch 117/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3097\n",
            "Epoch 118/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3079\n",
            "Epoch 119/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3075\n",
            "Epoch 120/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3102\n",
            "Epoch 121/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3098\n",
            "Epoch 122/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3102\n",
            "Epoch 123/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3115\n",
            "Epoch 124/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3084\n",
            "Epoch 125/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3156\n",
            "Epoch 126/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3057\n",
            "Epoch 127/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3046\n",
            "Epoch 128/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3087\n",
            "Epoch 129/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3104\n",
            "Epoch 130/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3057\n",
            "Epoch 131/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3093\n",
            "Epoch 132/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3070\n",
            "Epoch 133/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3069\n",
            "Epoch 134/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3091\n",
            "Epoch 135/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3078\n",
            "Epoch 136/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3135\n",
            "Epoch 137/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3173\n",
            "Epoch 138/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3166\n",
            "Epoch 139/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3098\n",
            "Epoch 140/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3163\n",
            "Epoch 141/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3150\n",
            "Epoch 142/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3096\n",
            "Epoch 143/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3065\n",
            "Epoch 144/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3072\n",
            "Epoch 145/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3163\n",
            "Epoch 146/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3058\n",
            "Epoch 147/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3148\n",
            "Epoch 148/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3068\n",
            "Epoch 149/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3152\n",
            "Epoch 150/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.3114\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdfb3916410>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "CBhIz2mNJHZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(input_signal, encoded3)                    # Model of Encoder is Defined here  "
      ],
      "metadata": {
        "id": "BYWkzH-JdD-z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder "
      ],
      "metadata": {
        "id": "quDydVnmJMJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = Input(shape=(n,))                          # Model for decoder is defined here  \n",
        "\n",
        "decoder_1 = autoencoder.layers[-2](encoded_input)          # Second last layer of the defined Autoencoder \n",
        "decoder_2 = autoencoder.layers[-1](decoder_1)              # Last layer of the defined Autoencoder \n",
        "decoder = Model(encoded_input, decoder_2)                                 "
      ],
      "metadata": {
        "id": "AtTTid3VdHRz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Test data "
      ],
      "metadata": {
        "id": "1zr1VftzNtaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = 10000                                       # Size of test samples \n",
        "                                                           \n",
        "test_labels = np.random.randint(L_o_m,size=test_samples)   # Test data of size N is created with all values enclosed between 0 and M\n",
        "test_data = []\n",
        "\n",
        "for i in test_labels:\n",
        "    test_vector = np.zeros(L_o_m)                          # Numpy array of size M is created with all entries equal to zero \n",
        "    test_vector[i] = 1                                     # performing One hot encoding on each entry of N \n",
        "    test_data.append(test_vector)\n",
        "    \n",
        "test_data = np.array(test_data)                            # Test data is converted to numpy array \n",
        "print(test_data.shape)                                     # Shape of test_data is given by (N*M)"
      ],
      "metadata": {
        "id": "1sMlQgCUdLvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621bcd21-4be7-48dc-96fc-a114e28c9b28"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_num = 99                                              # Verifying the onehot encoding on generated test data \n",
        "print (test_data[test_num],test_labels[test_num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm9hoWPPdNVT",
        "outputId": "8a435ecc-92ee-41fc-8272-97de2cf4eaed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constellation Diagram\n",
        "Every message in the message space is encode to draw constellation diagram "
      ],
      "metadata": {
        "id": "1CulcMPYOglR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scatter_plot = []                                                                \n",
        "for i in range(0,L_o_m):                                   # For all the messages in the message space \n",
        "    array1 = np.zeros(L_o_m)\n",
        "    \n",
        "    array1[i] = 1                                          # onehot encoding of the each message\n",
        "    scatter_plot.append(encoder.predict(np.expand_dims(array1,axis=0)))         \n",
        "                                                           # Encoding every possible entry of Messages needed to be sent \n",
        "scatter_plot = np.array(scatter_plot)                      # As you can see for each of the sixteen possible values there is a complex representation \n",
        "print (scatter_plot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5O_d2o9dV-s",
        "outputId": "98df9b05-6bf8-42e9-d1b0-aac47d597498"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scatter_plot = scatter_plot.reshape(L_o_m,2,1)             # Constellation diagram\n",
        "plt.scatter(scatter_plot[:,0],scatter_plot[:,1] )          # quadrature phase shift keying (QPSK) for (2,2)\n",
        "plt.axis((-2.5,3.5,-2.5,2.5))                              # Rotated 16 PSK constellation for (2,4)\n",
        "\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "eUplxgHfdoFz",
        "outputId": "e10ec2f5-fc8d-463b-c7dc-0c1ca8eac468"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Bit Error Rate "
      ],
      "metadata": {
        "id": "ztU93yDPO2Lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frange(i, j, jump):                                    # For represnting SNR after overy 0.5 db interval \n",
        "  while i < j:\n",
        "    yield i\n",
        "    i += jump"
      ],
      "metadata": {
        "id": "jjRI-2yKdrNz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNR_range = list(frange(-4,12,0.5))                        # Range of SNR \n",
        "print(len(SNR_range))                                      # In total there are 25 intervals\n",
        "  \n",
        "BER = [None]*len(SNR_range)                                                  \n",
        "                                                 \n",
        "for x in range(0,len(SNR_range)):                          # for each of the value of SNR \n",
        "    EbNo=10.0**(SNR_range[x]/10.0)                         # to covert each value of SNR from db's to EbNo\n",
        "    noise_std = np.sqrt(1/(2*R*EbNo))                      # Standard deviation of the added noise layer \n",
        "    mean = 0                                               # Mean of the added noise layer \n",
        "    errors = 0\n",
        "    \n",
        "    noise = noise_std * np.random.randn(test_samples,n)    # Noise is added to encoded data\n",
        "    encoded_vector = encoder.predict(test_data)            # Encoded test data \n",
        "    noise_added_vector = encoded_vector + noise            # Encoded test data + Noise\n",
        "\n",
        "    decoded_vector =  decoder.predict(noise_added_vector)  # Decoded data \n",
        "    pred_output = np.argmax(decoded_vector,axis=1)         \n",
        "                                                  # As the decoder last layer is Softmax so the index with the highest probabilty is chosen\n",
        "    errors = (pred_output != test_labels)         # It checks for each of the test_sample is the predicted value is same as the original value \n",
        "    \n",
        "    errors =  errors.astype(int).sum()                     # Adds up the total Error bits in each of the iteration for N values  \n",
        "        \n",
        "    BER[x] = errors / test_samples                         # BER is given by total  wrongly identified examples over total number of Examples\n",
        "\n",
        "    print ('SNR (Signal to noise ratio):',SNR_range[x],'BER (Bit Error Rate):',BER[x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CICwsaTdx5c",
        "outputId": "04b23fab-0c2a-4cee-d88a-06f2b5ac527a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "SNR (Signal to noise ratio): -4 BER (Bit Error Rate): 0.6528\n",
            "SNR (Signal to noise ratio): -3.5 BER (Bit Error Rate): 0.6286\n",
            "SNR (Signal to noise ratio): -3.0 BER (Bit Error Rate): 0.6128\n",
            "SNR (Signal to noise ratio): -2.5 BER (Bit Error Rate): 0.5886\n",
            "SNR (Signal to noise ratio): -2.0 BER (Bit Error Rate): 0.5641\n",
            "SNR (Signal to noise ratio): -1.5 BER (Bit Error Rate): 0.538\n",
            "SNR (Signal to noise ratio): -1.0 BER (Bit Error Rate): 0.5149\n",
            "SNR (Signal to noise ratio): -0.5 BER (Bit Error Rate): 0.4851\n",
            "SNR (Signal to noise ratio): 0.0 BER (Bit Error Rate): 0.4547\n",
            "SNR (Signal to noise ratio): 0.5 BER (Bit Error Rate): 0.4195\n",
            "SNR (Signal to noise ratio): 1.0 BER (Bit Error Rate): 0.3854\n",
            "SNR (Signal to noise ratio): 1.5 BER (Bit Error Rate): 0.3591\n",
            "SNR (Signal to noise ratio): 2.0 BER (Bit Error Rate): 0.3281\n",
            "SNR (Signal to noise ratio): 2.5 BER (Bit Error Rate): 0.2884\n",
            "SNR (Signal to noise ratio): 3.0 BER (Bit Error Rate): 0.2496\n",
            "SNR (Signal to noise ratio): 3.5 BER (Bit Error Rate): 0.2235\n",
            "SNR (Signal to noise ratio): 4.0 BER (Bit Error Rate): 0.1942\n",
            "SNR (Signal to noise ratio): 4.5 BER (Bit Error Rate): 0.1627\n",
            "SNR (Signal to noise ratio): 5.0 BER (Bit Error Rate): 0.1388\n",
            "SNR (Signal to noise ratio): 5.5 BER (Bit Error Rate): 0.1146\n",
            "SNR (Signal to noise ratio): 6.0 BER (Bit Error Rate): 0.0902\n",
            "SNR (Signal to noise ratio): 6.5 BER (Bit Error Rate): 0.0711\n",
            "SNR (Signal to noise ratio): 7.0 BER (Bit Error Rate): 0.0506\n",
            "SNR (Signal to noise ratio): 7.5 BER (Bit Error Rate): 0.0379\n",
            "SNR (Signal to noise ratio): 8.0 BER (Bit Error Rate): 0.0251\n",
            "SNR (Signal to noise ratio): 8.5 BER (Bit Error Rate): 0.02\n",
            "SNR (Signal to noise ratio): 9.0 BER (Bit Error Rate): 0.0123\n",
            "SNR (Signal to noise ratio): 9.5 BER (Bit Error Rate): 0.0085\n",
            "SNR (Signal to noise ratio): 10.0 BER (Bit Error Rate): 0.0056\n",
            "SNR (Signal to noise ratio): 10.5 BER (Bit Error Rate): 0.003\n",
            "SNR (Signal to noise ratio): 11.0 BER (Bit Error Rate): 0.002\n",
            "SNR (Signal to noise ratio): 11.5 BER (Bit Error Rate): 0.0006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot of Bit Error Rate against Range of SNR"
      ],
      "metadata": {
        "id": "4DWbspcUp439"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.plot(SNR_range, BER, 'bo',label='Autoencoder(2,4)')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('SNR Range')\n",
        "plt.ylabel('Block Error Rate')\n",
        "plt.grid()\n",
        "plt.legend(loc='upper right',ncol = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "GrswTvJod9Xs",
        "outputId": "837526bf-1148-4e8e-ad69-0e978ce65e62"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fdfae189310>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}