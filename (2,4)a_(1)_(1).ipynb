{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(2,4)a_(1)_(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Required Libraries  "
      ],
      "metadata": {
        "id": "CW8m7EYH-NH6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rpECXu6zYkIF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Input, Dense, GaussianNoise,Lambda\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.models import load_model\n",
        "from keras.constraints import max_norm \n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "from tensorflow.keras.utils import set_random_seed\n",
        "set_random_seed(3)                                                 \n",
        "from scipy import interpolate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parameters Declaration \n",
        "Lenght of Message space, Number of bits per symbol, number of channel uses\n",
        "and Rate of communication is defined here. "
      ],
      "metadata": {
        "id": "2zTzktIN_LAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L_o_m  = 16                                               # Lenght of Message space(M) given by 2^number of bits \n",
        "bits = np.log2(L_o_m)                                     # Number of bits \n",
        "bits = int(bits)                                          # Converting it to int \n",
        "n = 2                                                     # Number of channels(n) \n",
        "R = bits/n                                                # Communication rate(R) given by number of bits divided by number of channels\n",
        "\n",
        "print ('Lenght of Message space (M):',L_o_m,'Number of bits (k):',bits,'Number of channels (n):',n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqlokJnxa0P-",
        "outputId": "4c4aa506-b402-47e3-ff0c-be458986c95d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lenght of Message space (M): 16 Number of bits (k): 4 Number of channels (n): 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating training data"
      ],
      "metadata": {
        "id": "rHe_SSueADk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = 100000\n",
        "labels = np.random.randint(L_o_m , size=samples)          # generating 100000 random numbers whose values are enclosed between 0 and (M-1)"
      ],
      "metadata": {
        "id": "01xhM5MWa4Jl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performing Onehot Encoding\n",
        "Each of the message in generated message space is onehot encoded. "
      ],
      "metadata": {
        "id": "TJPJNPzJAko9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = []                                        # Creating a empty list \n",
        "for i in labels:                         \n",
        "    inp_vector = np.zeros(L_o_m)                          # Creating a numpy array of size M                                                    \n",
        "    inp_vector[i] = 1                                     # Performing one hot encoding \n",
        "    training_data.append(inp_vector) \n",
        "\n"
      ],
      "metadata": {
        "id": "fZA-OwDvboBl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = np.array(training_data)                   # Transforming data to numpy array\n",
        "print (training_data.shape)                               # Each of the sample out of the N generated samples is onehot encoded to vector of size M "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ppnpj4ubrsF",
        "outputId": "bb5957a3-d782-4f33-f94b-a9250448447c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifying the one hot encoding performed on the generated data.  \n"
      ],
      "metadata": {
        "id": "diWa01MlD-ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_list = [23,45,97,115,278,369]\n",
        "for i in check_list:\n",
        "    print(labels[i],training_data[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwwdatTObvhc",
        "outputId": "d142de3c-f87e-4081-d05f-6564d393e8ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "0 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "2 [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "7 [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the architecture of Autoencoder"
      ],
      "metadata": {
        "id": "H2uQEQoIFBWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_signal = Input(shape=(L_o_m,))                              # After performing one hot encoding each input is vector of size M\n",
        "encoded1 = Dense(L_o_m, activation='relu')(input_signal)          # First layer is dense layer with relu activation function and M nuerons  \n",
        "encoded2 = Dense(n, activation='linear')(encoded1)                # Second layer is dense layer with linear activaton function and n_channel nuerons \n",
        "encoded3 = Lambda(lambda x: np.sqrt(n)*K.l2_normalize(x,axis=1))(encoded2)      \n",
        "                                                                  # Normalisation is performed to met the physical constraints (Energy Constraint)\n",
        "                                                                  #encoded3 = BatchNormalization(gamma_constraint=max_norm(1.4142136))(encoded2) \n",
        "\n",
        "\n",
        "EbNo_train = 5.01187                                              # coverted 7 db of EbNo\n",
        "                                                                  # 10log(EbNo) = 7 db\n",
        "encoded4 = GaussianNoise(np.sqrt(1/(2*R*EbNo_train)))(encoded3)   # As Variance is given by (1/(2*R*EbNo_train) \n",
        "                                                                  # Gausian noise is added by this layer \n",
        "\n",
        "decoded1 = Dense(L_o_m, activation='relu')(encoded4)              # First layer of the decoder is dense layer with-\n",
        "                                                                  # -relu activation function and total M nuerons\n",
        "\n",
        "decoded2 = Dense(L_o_m, activation='softmax')(decoded1)           # Second layer of the decoder is dense layer with- \n",
        "                                                                  # -softmax activation function which outputs the probabilities \n",
        "\n",
        "\n",
        "autoencoder = Model(input_signal, decoded2)                       # Autoencoder model is defined here \n",
        "adam = Adam(learning_rate=0.001)                                  # Adam optimizer is used with learning rate 0.01 to minimise the loss \n",
        "\n",
        "autoencoder.compile(optimizer=adam, loss='categorical_crossentropy')    \n",
        "                                                                  # Autoencoder is compiled here and loss is defined as categorical crossentropy\n",
        "                                                                  # between the onehot encoded input vector and the output of the decoder "
      ],
      "metadata": {
        "id": "-FNphna1bxfk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary of Autoencoder"
      ],
      "metadata": {
        "id": "7xS2b5trFX2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print (autoencoder.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o2A_DywcfK1",
        "outputId": "aa73c6d6-490d-455e-9bd0-9499511a7c98"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 16)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 2)                 0         \n",
            "                                                                 \n",
            " gaussian_noise (GaussianNoi  (None, 2)                0         \n",
            " se)                                                             \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                48        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 626\n",
            "Trainable params: 626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model "
      ],
      "metadata": {
        "id": "KsIqAPGUFjdr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(training_data, training_data, epochs=150, batch_size=64)        # Autoencoder is fitted with the generated data                                         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zk1GFPac4-M",
        "outputId": "525151a2-0109-4ef6-e54f-e72ebcef4b5c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2210\n",
            "Epoch 2/150\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6247\n",
            "Epoch 3/150\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.5496\n",
            "Epoch 4/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5375\n",
            "Epoch 5/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5299\n",
            "Epoch 6/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5301\n",
            "Epoch 7/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5266\n",
            "Epoch 8/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5296\n",
            "Epoch 9/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5278\n",
            "Epoch 10/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5256\n",
            "Epoch 11/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5247\n",
            "Epoch 12/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5244\n",
            "Epoch 13/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5222\n",
            "Epoch 14/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5259\n",
            "Epoch 15/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5231\n",
            "Epoch 16/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5246\n",
            "Epoch 17/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5252\n",
            "Epoch 18/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5241\n",
            "Epoch 19/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5206\n",
            "Epoch 20/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5224\n",
            "Epoch 21/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5190\n",
            "Epoch 22/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5237\n",
            "Epoch 23/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5270\n",
            "Epoch 24/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5237\n",
            "Epoch 25/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5236\n",
            "Epoch 26/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5181\n",
            "Epoch 27/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5196\n",
            "Epoch 28/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5235\n",
            "Epoch 29/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5245\n",
            "Epoch 30/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5189\n",
            "Epoch 31/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5240\n",
            "Epoch 32/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5192\n",
            "Epoch 33/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5226\n",
            "Epoch 34/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5243\n",
            "Epoch 35/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5229\n",
            "Epoch 36/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5218\n",
            "Epoch 37/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5171\n",
            "Epoch 38/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5236\n",
            "Epoch 39/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5217\n",
            "Epoch 40/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5169\n",
            "Epoch 41/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5206\n",
            "Epoch 42/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5200\n",
            "Epoch 43/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5233\n",
            "Epoch 44/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5219\n",
            "Epoch 45/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5242\n",
            "Epoch 46/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5240\n",
            "Epoch 47/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5235\n",
            "Epoch 48/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5239\n",
            "Epoch 49/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5217\n",
            "Epoch 50/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5208\n",
            "Epoch 51/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5236\n",
            "Epoch 52/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5183\n",
            "Epoch 53/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5200\n",
            "Epoch 54/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5268\n",
            "Epoch 55/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5192\n",
            "Epoch 56/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5176\n",
            "Epoch 57/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5223\n",
            "Epoch 58/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5207\n",
            "Epoch 59/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5256\n",
            "Epoch 60/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5223\n",
            "Epoch 61/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5216\n",
            "Epoch 62/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5220\n",
            "Epoch 63/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5206\n",
            "Epoch 64/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5228\n",
            "Epoch 65/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5195\n",
            "Epoch 66/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5209\n",
            "Epoch 67/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5205\n",
            "Epoch 68/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5237\n",
            "Epoch 69/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5183\n",
            "Epoch 70/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5213\n",
            "Epoch 71/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5209\n",
            "Epoch 72/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5194\n",
            "Epoch 73/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5244\n",
            "Epoch 74/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5212\n",
            "Epoch 75/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5218\n",
            "Epoch 76/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5231\n",
            "Epoch 77/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5214\n",
            "Epoch 78/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5154\n",
            "Epoch 79/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5225\n",
            "Epoch 80/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5221\n",
            "Epoch 81/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5189\n",
            "Epoch 82/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5227\n",
            "Epoch 83/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5211\n",
            "Epoch 84/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5201\n",
            "Epoch 85/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5232\n",
            "Epoch 86/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5190\n",
            "Epoch 87/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5197\n",
            "Epoch 88/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5251\n",
            "Epoch 89/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5194\n",
            "Epoch 90/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5180\n",
            "Epoch 91/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5217\n",
            "Epoch 92/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5189\n",
            "Epoch 93/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5218\n",
            "Epoch 94/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5202\n",
            "Epoch 95/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5222\n",
            "Epoch 96/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5200\n",
            "Epoch 97/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5207\n",
            "Epoch 98/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5227\n",
            "Epoch 99/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5213\n",
            "Epoch 100/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5203\n",
            "Epoch 101/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5215\n",
            "Epoch 102/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5232\n",
            "Epoch 103/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5223\n",
            "Epoch 104/150\n",
            "1563/1563 [==============================] - 2s 2ms/step - loss: 0.5209\n",
            "Epoch 105/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5227\n",
            "Epoch 106/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5266\n",
            "Epoch 107/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5203\n",
            "Epoch 108/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5200\n",
            "Epoch 109/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5251\n",
            "Epoch 110/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5235\n",
            "Epoch 111/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5186\n",
            "Epoch 112/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5218\n",
            "Epoch 113/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5167\n",
            "Epoch 114/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5198\n",
            "Epoch 115/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5190\n",
            "Epoch 116/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5185\n",
            "Epoch 117/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5237\n",
            "Epoch 118/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5191\n",
            "Epoch 119/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5209\n",
            "Epoch 120/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5231\n",
            "Epoch 121/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5177\n",
            "Epoch 122/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5163\n",
            "Epoch 123/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5203\n",
            "Epoch 124/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5185\n",
            "Epoch 125/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5236\n",
            "Epoch 126/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5213\n",
            "Epoch 127/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5155\n",
            "Epoch 128/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5222\n",
            "Epoch 129/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5189\n",
            "Epoch 130/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5203\n",
            "Epoch 131/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5221\n",
            "Epoch 132/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5180\n",
            "Epoch 133/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5200\n",
            "Epoch 134/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5225\n",
            "Epoch 135/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5198\n",
            "Epoch 136/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5194\n",
            "Epoch 137/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5196\n",
            "Epoch 138/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5219\n",
            "Epoch 139/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5185\n",
            "Epoch 140/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5178\n",
            "Epoch 141/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5220\n",
            "Epoch 142/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5223\n",
            "Epoch 143/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5190\n",
            "Epoch 144/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5207\n",
            "Epoch 145/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5192\n",
            "Epoch 146/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5213\n",
            "Epoch 147/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5202\n",
            "Epoch 148/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5197\n",
            "Epoch 149/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5210\n",
            "Epoch 150/150\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 0.5216\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbf39377890>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "CBhIz2mNJHZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Model(input_signal, encoded3)                   # Model of Encoder is Defined here  "
      ],
      "metadata": {
        "id": "BYWkzH-JdD-z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoder "
      ],
      "metadata": {
        "id": "quDydVnmJMJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = Input(shape=(n,))                         # Model for decoder is defined here  \n",
        "\n",
        "decoder_1 = autoencoder.layers[-2](encoded_input)         # Second last layer of the defined Autoencoder \n",
        "decoder_2 = autoencoder.layers[-1](decoder_1)             # Last layer of the defined Autoencoder \n",
        "decoder = Model(encoded_input, decoder_2)                                 "
      ],
      "metadata": {
        "id": "AtTTid3VdHRz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Test data "
      ],
      "metadata": {
        "id": "1zr1VftzNtaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples = 10000                                      # Size of test samples \n",
        "                                                                                \n",
        "test_labels = np.random.randint(L_o_m,size=test_samples)  # Test data of size 10000 is created with all values enclosed between 0 and M\n",
        "test_data = []\n",
        "\n",
        "for i in test_labels:\n",
        "    test_vector = np.zeros(L_o_m)                         # Numpy array of size M is created with all entries equal to zero \n",
        "    test_vector[i] = 1                                    # performing One hot encoding on each entry of 10000\n",
        "    test_data.append(test_vector)\n",
        "    \n",
        "test_data = np.array(test_data)                           # Test data is converted to numpy array \n",
        "print(test_data.shape)                                    # Shape of test_data is given by (10000*M)"
      ],
      "metadata": {
        "id": "1sMlQgCUdLvr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3bc0e43-5454-4868-9dba-b6b1a339e344"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_num = 99                                             # Verifying the onehot encoding on generated test data \n",
        "print (test_data[test_num],test_labels[test_num])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm9hoWPPdNVT",
        "outputId": "3ca183b8-4034-4aad-fbf3-e01ef89cc5e2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constellation Diagram\n",
        "Every message in the message space is encode to draw constellation diagram "
      ],
      "metadata": {
        "id": "1CulcMPYOglR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scatter_plot = []                                                                \n",
        "for i in range(0,L_o_m):                                  # For all the messages in the message space \n",
        "    array1 = np.zeros(L_o_m)                              # Generating numpy array of size (L_o_m) with all entries equal to zero \n",
        "    \n",
        "    array1[i] = 1                                         # onehot encoding of the each message\n",
        "    scatter_plot.append(encoder.predict(np.expand_dims(array1,axis=0)))      # Encoding every possible entry of Messages needed to be sent \n",
        "scatter_plot = np.array(scatter_plot)                     # As you can see for each of the sixteen possible values there is a complex representation \n",
        "print (scatter_plot.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5O_d2o9dV-s",
        "outputId": "c6edd9d6-aa43-4ee7-af18-8c7533a7b4ed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scatter_plot = scatter_plot.reshape(L_o_m,2,1)            # Constellation diagram\n",
        "plt.scatter(scatter_plot[:,0],scatter_plot[:,1] )         # quadrature phase shift keying (QPSK) for (2,2)\n",
        "plt.axis((-2.5,3.5,-2.5,2.5))                             # Rotated 16 PSK constellation for (2,4)\n",
        "\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "eUplxgHfdoFz",
        "outputId": "3e8308de-ded0-4c65-ee4b-877142264986"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Bit Error Rate "
      ],
      "metadata": {
        "id": "ztU93yDPO2Lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frange(i, j, jump):                 # For represnting SNR after overy 0.5 db interval \n",
        "  while i < j:\n",
        "    yield i\n",
        "    i += jump"
      ],
      "metadata": {
        "id": "jjRI-2yKdrNz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SNR_range = list(frange(-4,12,0.5))                             # Range of SNR \n",
        "print(len(SNR_range))                                           # In total there are 25 intervals\n",
        "  \n",
        "BER = [None]*len(SNR_range)                                                  \n",
        "                                                 \n",
        "for x in range(0,len(SNR_range)):                               # for each of the value of SNR \n",
        "    EbNo=10.0**(SNR_range[x]/10.0)                              # to covert each value of SNR from db's\n",
        "    noise_std = np.sqrt(1/(2*R*EbNo))                           # Standard deviation of the added noise layer \n",
        "    mean = 0                                                    # Mean of the added noise layer \n",
        "    errors = 0\n",
        "    \n",
        "    noise = noise_std * np.random.randn(test_samples,n)         # Noise is added to encoded data\n",
        "    encoded_vector = encoder.predict(test_data)                 # Encoded test data \n",
        "    noise_added_vector = encoded_vector + noise                 # Encoded test data + Noise\n",
        "\n",
        "    decoded_vector =  decoder.predict(noise_added_vector)       # Decoded data \n",
        "    pred_output = np.argmax(decoded_vector,axis=1)         # As the decoder last layer is Softmax so the index with the highest probabilty is chosen\n",
        "    errors = (pred_output != test_labels)                  # It checks for each of the test_sample is the predicted value is same as the original value \n",
        "    \n",
        "    errors =  errors.astype(int).sum()                          # Adds up the total Error bits in each of the iteration for test_samples values  \n",
        "        \n",
        "    BER[x] = errors / test_samples                              # BER is given by total wrongly identified examples over total number of Examples\n",
        "\n",
        "    print ('SNR (Signal to noise ratio):',SNR_range[x],'BER (Bit Error Rate):',BER[x])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CICwsaTdx5c",
        "outputId": "e93683a1-eaf5-4c1b-9c46-6a598dab7e8a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n",
            "SNR (Signal to noise ratio): -4 BER (Bit Error Rate): 0.7223\n",
            "SNR (Signal to noise ratio): -3.5 BER (Bit Error Rate): 0.7088\n",
            "SNR (Signal to noise ratio): -3.0 BER (Bit Error Rate): 0.6977\n",
            "SNR (Signal to noise ratio): -2.5 BER (Bit Error Rate): 0.6833\n",
            "SNR (Signal to noise ratio): -2.0 BER (Bit Error Rate): 0.6719\n",
            "SNR (Signal to noise ratio): -1.5 BER (Bit Error Rate): 0.6466\n",
            "SNR (Signal to noise ratio): -1.0 BER (Bit Error Rate): 0.6148\n",
            "SNR (Signal to noise ratio): -0.5 BER (Bit Error Rate): 0.6104\n",
            "SNR (Signal to noise ratio): 0.0 BER (Bit Error Rate): 0.575\n",
            "SNR (Signal to noise ratio): 0.5 BER (Bit Error Rate): 0.5626\n",
            "SNR (Signal to noise ratio): 1.0 BER (Bit Error Rate): 0.536\n",
            "SNR (Signal to noise ratio): 1.5 BER (Bit Error Rate): 0.5144\n",
            "SNR (Signal to noise ratio): 2.0 BER (Bit Error Rate): 0.4945\n",
            "SNR (Signal to noise ratio): 2.5 BER (Bit Error Rate): 0.463\n",
            "SNR (Signal to noise ratio): 3.0 BER (Bit Error Rate): 0.4276\n",
            "SNR (Signal to noise ratio): 3.5 BER (Bit Error Rate): 0.4075\n",
            "SNR (Signal to noise ratio): 4.0 BER (Bit Error Rate): 0.3868\n",
            "SNR (Signal to noise ratio): 4.5 BER (Bit Error Rate): 0.3569\n",
            "SNR (Signal to noise ratio): 5.0 BER (Bit Error Rate): 0.3278\n",
            "SNR (Signal to noise ratio): 5.5 BER (Bit Error Rate): 0.3049\n",
            "SNR (Signal to noise ratio): 6.0 BER (Bit Error Rate): 0.2714\n",
            "SNR (Signal to noise ratio): 6.5 BER (Bit Error Rate): 0.2477\n",
            "SNR (Signal to noise ratio): 7.0 BER (Bit Error Rate): 0.2264\n",
            "SNR (Signal to noise ratio): 7.5 BER (Bit Error Rate): 0.1898\n",
            "SNR (Signal to noise ratio): 8.0 BER (Bit Error Rate): 0.1648\n",
            "SNR (Signal to noise ratio): 8.5 BER (Bit Error Rate): 0.1455\n",
            "SNR (Signal to noise ratio): 9.0 BER (Bit Error Rate): 0.116\n",
            "SNR (Signal to noise ratio): 9.5 BER (Bit Error Rate): 0.1057\n",
            "SNR (Signal to noise ratio): 10.0 BER (Bit Error Rate): 0.0832\n",
            "SNR (Signal to noise ratio): 10.5 BER (Bit Error Rate): 0.0681\n",
            "SNR (Signal to noise ratio): 11.0 BER (Bit Error Rate): 0.0564\n",
            "SNR (Signal to noise ratio): 11.5 BER (Bit Error Rate): 0.0407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot of Bit Error Rate against Range of SNR"
      ],
      "metadata": {
        "id": "4DWbspcUp439"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plt.plot(SNR_range, BER, 'bo',label='Autoencoder(2,4)')\n",
        "plt.yscale('log')\n",
        "plt.xlabel('SNR Range')\n",
        "plt.ylabel('Block Error Rate')\n",
        "plt.grid()\n",
        "plt.legend(loc='upper right',ncol = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "GrswTvJod9Xs",
        "outputId": "3ad76239-5ddb-4de1-cf32-16ddebd61ee1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fbf34d3cd50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}